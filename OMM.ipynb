{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "# the following neural network is to model the value function\n",
    "class MyNet(nn.Module):\n",
    "    def __init__(self, m, n):\n",
    "        super(MyNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(1 + m * n, 64)\n",
    "        self.fc2 = nn.Linear(64, 32)\n",
    "        self.fc3 = nn.Linear(32, 1)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "# x is 2 dim torch tensor with shape (m, n)\n",
    "    def forward(self, t, x):\n",
    "        #make x 1 dim\n",
    "        x = x.view(-1)\n",
    "        x = torch.cat((t, x), dim=0)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "    \n",
    "# The Gaussian policy returns torch tensor with shape (m, n)\n",
    "def Gaussian_Policy(net, t, q, A, B, gamma):\n",
    "    \n",
    "    bid_matrix  = torch.zeros(q.shape)\n",
    "    ask_matrix  = torch.zeros(q.shape)\n",
    "\n",
    "    for i in range(A.shape[0]):\n",
    "        for j in range(A.shape[1]):\n",
    "            x = torch.zeros(q.shape)\n",
    "            x[i, j] = 1\n",
    "            mean_bid = A[i, j] / (2 * B[i, j]) + 0.5 * (net.forward(t, q) - net.forward(t, q + x))\n",
    "            mean_ask = A[i, j] / (2 * B[i, j]) + 0.5 * (net.forward(t, q) - net.forward(t, q - x))\n",
    "            variance = gamma / (2 * B[i, j])\n",
    "            std = torch.sqrt(variance)\n",
    "            bid_matrix[i, j] = torch.normal(mean_bid, std)\n",
    "            ask_matrix[i, j] = torch.normal(mean_ask, std)\n",
    "\n",
    "    return bid_matrix, ask_matrix\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import scipy.stats as scistat\n",
    "\n",
    "def Market_Order_Simulation(dt, A, B, bid_matrix, ask_matrix):\n",
    "    orders = torch.zeros(bid_matrix.shape)\n",
    "    buy_orders = torch.zeros(bid_matrix.shape)\n",
    "    sell_orders = torch.zeros(bid_matrix.shape)\n",
    "    m = bid_matrix.shape[0]\n",
    "    n = bid_matrix.shape[1]\n",
    "    for i in range(m):\n",
    "        for j in range(n):\n",
    "            intensity_bid = A[i, j] - B[i, j] * bid_matrix[i, j]\n",
    "            intensity_ask = A[i, j] - B[i, j] * ask_matrix[i, j]\n",
    "            buy_orders[i, j] = torch.poisson(intensity_bid * dt)\n",
    "            sell_orders[i, j] = torch.poisson(intensity_ask * dt)\n",
    "            orders[i, j] = buy_orders[i, j] - sell_orders[i, j]\n",
    "\n",
    "    return [orders, buy_orders, sell_orders]\n",
    "\n",
    "# this function returns the inventory path\n",
    "def Train_Data_Simulation(T, dt, A, B, gamma, net):\n",
    "    N = int(T / dt)\n",
    "    m = A.shape[0]\n",
    "    n = A.shape[1]\n",
    "    q = torch.zeros((N, m, n))\n",
    "    buy = torch.zeros((N, m, n))\n",
    "    sell = torch.zeros((N, m, n))\n",
    "\n",
    "    for count in range(N - 1):\n",
    "        t = torch.Tensor([count * dt])\n",
    "        bid_matrix, ask_matrix = Gaussian_Policy(net, t, q[count], A, B, gamma)\n",
    "        orders = Market_Order_Simulation(dt, A, B, bid_matrix, ask_matrix)[0]\n",
    "        buy[count] = Market_Order_Simulation(dt, A, B, bid_matrix, ask_matrix)[1]\n",
    "        sell[count] = Market_Order_Simulation(dt, A, B, bid_matrix, ask_matrix)[2]\n",
    "        q[count + 1] = q[count] + orders\n",
    "    \n",
    "    return q, buy, sell\n",
    "\n",
    "# this function returns the stock prices path\n",
    "def Stock_Prices_Simulation(T, dt, mu, sigma, S0):\n",
    "    N = int(T / dt)\n",
    "    S = torch.zeros(N)\n",
    "    S[0] = S0\n",
    "    for count in range(N - 1):\n",
    "        S[count + 1] = S[count] + mu * S[count] * dt + sigma * S[count] * math.sqrt(dt) * torch.normal(0.0, 1.0, size=(1,))\n",
    "    return S\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#the following are option greeks' functions\n",
    "def d1(S, K, r, sigma, T):\n",
    "    return (np.log(S/K) + (r+sigma*sigma/2)*T)/(sigma*np.sqrt(T))\n",
    "\n",
    "def d2(S, K, r, sigma, T):\n",
    "    return d1(S, K, r, sigma, T) - sigma*np.sqrt(T)\n",
    "\n",
    "def Gamma(S, K, r, sigma, T):\n",
    "    return scistat.norm.pdf(d1(S, K, r, sigma, T))/(S*sigma*np.sqrt(T))\n",
    "\n",
    "def Theta(S, K, r, sigma, T):\n",
    "    aux1 = -S*scistat.norm.pdf(d1(S, K, r, sigma, T))*sigma/(2*np.sqrt(T))\n",
    "    aux2 = -r*K*np.exp(-r*T)*scistat.norm.cdf(d2(S, K, r, sigma, T))\n",
    "    return aux1+aux2\n",
    "\n",
    "\n",
    "def Options_Theta(Vol_surface, S0, r, mu, sigma, T, dt, Maturities, Strikes):\n",
    "    N = int(T / dt)\n",
    "    m = Vol_surface.shape[0]\n",
    "    n = Vol_surface.shape[1]\n",
    "    theta = torch.zeros((N, m, n))\n",
    "    S = Stock_Prices_Simulation(T, dt, mu, sigma, S0)\n",
    "    for count in range(N):\n",
    "        t = count * dt\n",
    "        for i in range(m):\n",
    "            for j in range(n):\n",
    "                theta[count, i, j] = Theta(S[count], Strikes[i], r, Vol_surface[i, j], Maturities[j] - t)\n",
    "    return theta\n",
    "\n",
    "\n",
    "def Options_Gamma(Vol_surface, S0, r, mu, sigma, T, dt, Maturities, Strikes):\n",
    "    N = int(T / dt)\n",
    "    m = Vol_surface.shape[0]\n",
    "    n = Vol_surface.shape[1]\n",
    "    gamma = torch.zeros((N, m, n))\n",
    "    S = Stock_Prices_Simulation(T, dt, mu, sigma, S0)\n",
    "    for count in range(N):\n",
    "        t = count * dt\n",
    "        for i in range(m):\n",
    "            for j in range(n):\n",
    "                gamma[count, i, j] = Gamma(S[count], Strikes[i], r, Vol_surface[i, j], Maturities[j] - t)\n",
    "    return gamma\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "def option_loss(Vol_surface, S0, q, mu, sigma, Strikes, Maturities, r, T, dt):\n",
    "    N = int(T / dt)\n",
    "    m = Vol_surface.shape[0]\n",
    "    n = Vol_surface.shape[1]\n",
    "    loss = torch.zeros(N)\n",
    "    for count in range(N):\n",
    "        t = count * dt\n",
    "        loss[count] =  torch.sum((Options_Theta(Vol_surface, S0, r, mu, sigma, T, dt, Maturities, Strikes)[count] + 0.5 * Options_Gamma(Vol_surface, S0, r, mu, sigma, T, dt, Maturities, Strikes)[count]) * q[count]) \n",
    "    return loss\n",
    "\n",
    "\n",
    "def inventory_loss(A, B, q, buy, sell, net, T, dt):\n",
    "    N = int(T / dt)\n",
    "    m = A.shape[0]\n",
    "    n = A.shape[1]\n",
    "    loss = torch.zeros(N)\n",
    "    for count in range(N):\n",
    "        t = torch.tensor([count * dt])\n",
    "        loss1 = torch.sum((A / (2 * B)) * (buy[count] + sell[count])) + 0.5 * net.forward(t, q[count]) * torch.sum(buy[count] + sell[count]) \n",
    "        loss2 = torch.tensor([0.0])\n",
    "        for i in range(m):\n",
    "            for j in range(n):\n",
    "                x = torch.zeros((m, n))\n",
    "                x[i, j] = 1\n",
    "                loss2 += net.forward(t, q[count] + x) * buy[count, i, j] + net.forward(t, q[count] - x) * sell[count, i, j]\n",
    "        loss[count] = loss1 - loss2\n",
    "        \n",
    "    return loss\n",
    "\n",
    "def value_function_loss(T, dt, q, net):\n",
    "    N = int(T / dt)\n",
    "    dt = torch.tensor([dt])\n",
    "    loss = torch.zeros(N)\n",
    "    for count in range(N - 1):\n",
    "        t = torch.tensor([count * dt])\n",
    "        loss[count] = (net.forward(t + dt, q[count + 1]) - net.forward(t, q[count])) / dt\n",
    "    return loss\n",
    "\n",
    "\n",
    "def constant_loss(gamma, B, T, dt):\n",
    "    N = int(T / dt)\n",
    "    m = B.shape[0]\n",
    "    n = B.shape[1]\n",
    "    loss = torch.zeros(N)\n",
    "    for count in range(N):\n",
    "        loss[count] = gamma * ((m * n * 1.79817986835) + torch.sum(torch.log(gamma / (2 * B))))\n",
    "    return loss\n",
    "\n",
    "def total_loss(Vol_surface, S0, q, mu, sigma, Strikes, Maturities, r, T, dt, A, B, buy, sell, net, gamma):\n",
    "    loss1 = option_loss(Vol_surface, S0, q, mu, sigma, Strikes, Maturities, r, T, dt)[:-1]\n",
    "    loss2 = inventory_loss(A, B, q, buy, sell, net, T, dt)[: -1]\n",
    "    loss3 = value_function_loss(T, dt, q, net)[:-1]\n",
    "    loss4 = constant_loss(gamma, B, T, dt)[:-1]\n",
    "    loss = 0.5 * dt * torch.sum((loss1 + loss2 + loss3 - loss4)**2)\n",
    "    return loss\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the neural network\n",
    "def train(net, Vol_surface, S0, mu, sigma, Strikes, Maturities, r, T, dt, A, B, gamma, lr, epochs):\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    net = net.to(device)\n",
    "    Vol_surface = Vol_surface.to(device)\n",
    "    Strikes = Strikes.to(device)\n",
    "    Maturities = Maturities.to(device)\n",
    "    A = A.to(device)\n",
    "    B = B.to(device)\n",
    "    q, buy, sell = Train_Data_Simulation(T, dt, A, B, gamma, net)\n",
    "    q = q.to(device)\n",
    "    buy = buy.to(device)\n",
    "    sell = sell.to(device)\n",
    "\n",
    "\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "    loss_record = []\n",
    "    for epoch in range(epochs):\n",
    "        optimizer.zero_grad()\n",
    "        loss = total_loss(Vol_surface, S0, q, mu, sigma, Strikes, Maturities, r, T, dt, A, B, buy, sell, net, gamma)\n",
    "        loss_record.append(loss)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        print('epoch {}, loss {}'.format(epoch, loss.item()))\n",
    "\n",
    "    return net, loss_record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "Vol_surface = torch.tensor([[0.2, 0.3], [0.4, 0.5]])\n",
    "S0 = 100\n",
    "r = 0.05\n",
    "T = 1\n",
    "dt = 0.01\n",
    "mu = 0.1\n",
    "sigma = 0.2\n",
    "gamma = 0.05\n",
    "Maturities = torch.tensor([3, 5])\n",
    "Strikes = torch.tensor([90, 110])\n",
    "net = MyNet(2, 2)\n",
    "learning_rate = 0.01\n",
    "num_epochs = 30\n",
    "A = torch.tensor([[1.0, 2.0], [3.0, 4.0]])\n",
    "B = torch.tensor([[0.2, 0.3], [0.2, 0.5]])\n",
    "\n",
    "theta_matrix = Options_Theta(Vol_surface, S0, r, mu, sigma, T, dt, Maturities, Strikes)\n",
    "gamma_matrix = Options_Gamma(Vol_surface, S0, r, mu, sigma, T, dt, Maturities, Strikes)\n",
    "\n",
    "learning_rate = 0.01\n",
    "num_epochs = 30\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument mat2 in method wrapper_mm)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[277], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m net, loss \u001b[39m=\u001b[39m train(net, Vol_surface, S0, mu, sigma, Strikes, Maturities, r, T, dt, A, B, gamma, learning_rate, num_epochs)\n",
      "Cell \u001b[1;32mIn[275], line 10\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(net, Vol_surface, S0, mu, sigma, Strikes, Maturities, r, T, dt, A, B, gamma, lr, epochs)\u001b[0m\n\u001b[0;32m      8\u001b[0m A \u001b[39m=\u001b[39m A\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m      9\u001b[0m B \u001b[39m=\u001b[39m B\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m---> 10\u001b[0m q, buy, sell \u001b[39m=\u001b[39m Train_Data_Simulation(T, dt, A, B, gamma, net)\n\u001b[0;32m     11\u001b[0m q \u001b[39m=\u001b[39m q\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m     12\u001b[0m buy \u001b[39m=\u001b[39m buy\u001b[39m.\u001b[39mto(device)\n",
      "Cell \u001b[1;32mIn[214], line 31\u001b[0m, in \u001b[0;36mTrain_Data_Simulation\u001b[1;34m(T, dt, A, B, gamma, net)\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[39mfor\u001b[39;00m count \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(N \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m):\n\u001b[0;32m     30\u001b[0m     t \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mTensor([count \u001b[39m*\u001b[39m dt])\n\u001b[1;32m---> 31\u001b[0m     bid_matrix, ask_matrix \u001b[39m=\u001b[39m Gaussian_Policy(net, t, q[count], A, B, gamma)\n\u001b[0;32m     32\u001b[0m     orders \u001b[39m=\u001b[39m Market_Order_Simulation(dt, A, B, bid_matrix, ask_matrix)[\u001b[39m0\u001b[39m]\n\u001b[0;32m     33\u001b[0m     buy[count] \u001b[39m=\u001b[39m Market_Order_Simulation(dt, A, B, bid_matrix, ask_matrix)[\u001b[39m1\u001b[39m]\n",
      "Cell \u001b[1;32mIn[174], line 34\u001b[0m, in \u001b[0;36mGaussian_Policy\u001b[1;34m(net, t, q, A, B, gamma)\u001b[0m\n\u001b[0;32m     32\u001b[0m x \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mzeros(q\u001b[39m.\u001b[39mshape)\n\u001b[0;32m     33\u001b[0m x[i, j] \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m---> 34\u001b[0m mean_bid \u001b[39m=\u001b[39m A[i, j] \u001b[39m/\u001b[39m (\u001b[39m2\u001b[39m \u001b[39m*\u001b[39m B[i, j]) \u001b[39m+\u001b[39m \u001b[39m0.5\u001b[39m \u001b[39m*\u001b[39m (net\u001b[39m.\u001b[39;49mforward(t, q) \u001b[39m-\u001b[39m net\u001b[39m.\u001b[39mforward(t, q \u001b[39m+\u001b[39m x))\n\u001b[0;32m     35\u001b[0m mean_ask \u001b[39m=\u001b[39m A[i, j] \u001b[39m/\u001b[39m (\u001b[39m2\u001b[39m \u001b[39m*\u001b[39m B[i, j]) \u001b[39m+\u001b[39m \u001b[39m0.5\u001b[39m \u001b[39m*\u001b[39m (net\u001b[39m.\u001b[39mforward(t, q) \u001b[39m-\u001b[39m net\u001b[39m.\u001b[39mforward(t, q \u001b[39m-\u001b[39m x))\n\u001b[0;32m     36\u001b[0m variance \u001b[39m=\u001b[39m gamma \u001b[39m/\u001b[39m (\u001b[39m2\u001b[39m \u001b[39m*\u001b[39m B[i, j])\n",
      "Cell \u001b[1;32mIn[174], line 17\u001b[0m, in \u001b[0;36mMyNet.forward\u001b[1;34m(self, t, x)\u001b[0m\n\u001b[0;32m     15\u001b[0m x \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39mview(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m     16\u001b[0m x \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcat((t, x), dim\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[1;32m---> 17\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfc1(x)\n\u001b[0;32m     18\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrelu(x)\n\u001b[0;32m     19\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfc2(x)\n",
      "File \u001b[1;32mc:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\lib\\site-packages\\torch\\nn\\modules\\module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\lib\\site-packages\\torch\\nn\\modules\\linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m--> 114\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mlinear(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument mat2 in method wrapper_mm)"
     ]
    }
   ],
   "source": [
    "net, loss = train(net, Vol_surface, S0, mu, sigma, Strikes, Maturities, r, T, dt, A, B, gamma, learning_rate, num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(65.2333, grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.3375, 0.2461],\n",
      "        [0.4124, 0.5485]], grad_fn=<CopySlices>)\n",
      "tensor([[0.1838, 0.6574],\n",
      "        [0.4161, 0.5759]], grad_fn=<CopySlices>)\n"
     ]
    }
   ],
   "source": [
    "#let t be a tensor scalar\n",
    "t = torch.tensor([1.0])\n",
    "x = torch.tensor([[1.0, 2.0], [3.0, 4.0]])\n",
    "# set random seed \n",
    "torch.manual_seed(0)\n",
    "net = MyNet(2, 2)\n",
    "\n",
    "# test the Gaussian policy\n",
    "A = torch.tensor([[1.0, 2.0], [3.0, 4.0]])\n",
    "B = torch.tensor([[1.0, 2.0], [3.0, 4.0]])\n",
    "q = torch.tensor([[1.0, 2.0], [3.0, 4.0]])\n",
    "gamma = 0.1\n",
    "bid_matrix, ask_matrix = Gaussian_Policy(net, t, q, A, B, gamma)\n",
    "\n",
    "print(bid_matrix)\n",
    "print(ask_matrix)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pvlib",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
