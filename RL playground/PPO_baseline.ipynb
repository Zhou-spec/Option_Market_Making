{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "def loc(nb):\n",
    "    cells = load(open(nb))['cells']\n",
    "    return sum(len(c['source']) for c in cells if c['cell_type'] == 'code')\n",
    "\n",
    "def run(ipynb_files):\n",
    "    return sum(loc(nb) for nb in ipynb_files)\n",
    "\n",
    "# the following neural network is to model the value function\n",
    "class MyNet(nn.Module):\n",
    "    def __init__(self, m, n):\n",
    "        super(MyNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(1 + m * n, 64)\n",
    "        self.fc2 = nn.Linear(64, 32)\n",
    "        self.fc3 = nn.Linear(32, 1)\n",
    "        self.relu = nn.ReLU(inplace=False)\n",
    "\n",
    "# x is 2 dim torch tensor with shape (m, n)\n",
    "    def forward(self, t, x):\n",
    "        #make x 1 dim\n",
    "        x = x.view(-1)\n",
    "        x = torch.cat((t, x), dim=0)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "    \n",
    "# The Gaussian policy returns torch tensor with shape (m, n)\n",
    "def Gaussian_Policy(net, t, q, A, B, gamma):\n",
    "    \n",
    "    bid_matrix  = torch.zeros(q.shape)\n",
    "    ask_matrix  = torch.zeros(q.shape)\n",
    "\n",
    "    for i in range(A.shape[0]):\n",
    "        for j in range(A.shape[1]):\n",
    "            x = torch.zeros(q.shape)\n",
    "            x[i, j] = 1\n",
    "            mean_bid = A[i, j] / (2 * B[i, j]) + 0.5 * (net.forward(t, q) - net.forward(t, q + x))\n",
    "            mean_ask = A[i, j] / (2 * B[i, j]) + 0.5 * (net.forward(t, q) - net.forward(t, q - x))\n",
    "            variance = gamma / (2 * B[i, j])\n",
    "            std = torch.sqrt(variance)\n",
    "            bid_matrix[i, j] = torch.normal(mean_bid, std)\n",
    "            ask_matrix[i, j] = torch.normal(mean_ask, std)\n",
    "\n",
    "    return bid_matrix, ask_matrix\n",
    "    \n",
    "\n",
    "import math\n",
    "import scipy.stats as scistat\n",
    "\n",
    "def Market_Order_Simulation(dt, A, B, bid_matrix, ask_matrix):\n",
    "    orders = torch.zeros(bid_matrix.shape)\n",
    "    buy_orders = torch.zeros(bid_matrix.shape)\n",
    "    sell_orders = torch.zeros(bid_matrix.shape)\n",
    "    m = bid_matrix.shape[0]\n",
    "    n = bid_matrix.shape[1]\n",
    "    for i in range(m):\n",
    "        for j in range(n):\n",
    "            intensity_bid = A[i, j] - B[i, j] * bid_matrix[i, j]\n",
    "            intensity_ask = A[i, j] - B[i, j] * ask_matrix[i, j]\n",
    "            buy_orders[i, j] = torch.poisson(intensity_bid * dt)\n",
    "            sell_orders[i, j] = torch.poisson(intensity_ask * dt)\n",
    "            orders[i, j] = buy_orders[i, j] - sell_orders[i, j]\n",
    "\n",
    "    return [orders, buy_orders, sell_orders]\n",
    "\n",
    "# this function returns the inventory path\n",
    "def Train_Data_Simulation(T, dt, A, B, gamma, net):\n",
    "    N = int(T / dt)\n",
    "    m = A.shape[0]\n",
    "    n = A.shape[1]\n",
    "    q = torch.zeros((N, m, n))\n",
    "    buy = torch.zeros((N, m, n))\n",
    "    sell = torch.zeros((N, m, n))\n",
    "    bid = torch.zeros((N, m, n))\n",
    "    ask = torch.zeros((N, m, n))\n",
    "\n",
    "    for count in range(N - 1):\n",
    "        t = torch.Tensor([count * dt])\n",
    "        bid_matrix, ask_matrix = Gaussian_Policy(net, t, q[count], A, B, gamma)\n",
    "        bid[count] = bid_matrix\n",
    "        ask[count] = ask_matrix\n",
    "        orders = Market_Order_Simulation(dt, A, B, bid_matrix, ask_matrix)[0]\n",
    "        buy[count] = Market_Order_Simulation(dt, A, B, bid_matrix, ask_matrix)[1]\n",
    "        sell[count] = Market_Order_Simulation(dt, A, B, bid_matrix, ask_matrix)[2]\n",
    "        q[count + 1] = q[count] + orders\n",
    "    \n",
    "    return q, buy, sell, bid, ask\n",
    "\n",
    "# this function returns the stock prices path\n",
    "def Stock_Prices_Simulation(T, dt, mu, sigma, S0):\n",
    "    N = int(T / dt)\n",
    "    S = torch.zeros(N)\n",
    "    S[0] = S0\n",
    "    for count in range(N - 1):\n",
    "        S[count + 1] = S[count] + mu * S[count] * dt + sigma * S[count] * math.sqrt(dt) * torch.normal(0.0, 1.0, size=(1,))\n",
    "    return S\n",
    "\n",
    "\n",
    "#the following are option greeks' functions\n",
    "def d1(S, K, r, sigma, T):\n",
    "    return (np.log(S/K) + (r+sigma*sigma/2)*T)/(sigma*np.sqrt(T))\n",
    "\n",
    "def d2(S, K, r, sigma, T):\n",
    "    return d1(S, K, r, sigma, T) - sigma*np.sqrt(T)\n",
    "\n",
    "def Gamma(S, K, r, sigma, T):\n",
    "    return scistat.norm.pdf(d1(S, K, r, sigma, T))/(S*sigma*np.sqrt(T))\n",
    "\n",
    "def Theta(S, K, r, sigma, T):\n",
    "    aux1 = -S*scistat.norm.pdf(d1(S, K, r, sigma, T))*sigma/(2*np.sqrt(T))\n",
    "    aux2 = -r*K*np.exp(-r*T)*scistat.norm.cdf(d2(S, K, r, sigma, T))\n",
    "    return aux1+aux2\n",
    "\n",
    "\n",
    "def Options_Theta(Vol_surface, S0, r, mu, sigma, T, dt, Maturities, Strikes):\n",
    "    N = int(T / dt)\n",
    "    m = Vol_surface.shape[0]\n",
    "    n = Vol_surface.shape[1]\n",
    "    theta = torch.zeros((N, m, n))\n",
    "    S = Stock_Prices_Simulation(T, dt, mu, sigma, S0)\n",
    "    for count in range(N):\n",
    "        t = count * dt\n",
    "        for i in range(m):\n",
    "            for j in range(n):\n",
    "                theta[count, i, j] = Theta(S[count], Strikes[i], r, Vol_surface[i, j], Maturities[j] - t)\n",
    "    return theta\n",
    "\n",
    "\n",
    "def Options_Gamma(Vol_surface, S0, r, mu, sigma, T, dt, Maturities, Strikes):\n",
    "    N = int(T / dt)\n",
    "    m = Vol_surface.shape[0]\n",
    "    n = Vol_surface.shape[1]\n",
    "    gamma = torch.zeros((N, m, n))\n",
    "    S = Stock_Prices_Simulation(T, dt, mu, sigma, S0)\n",
    "    for count in range(N):\n",
    "        t = count * dt\n",
    "        for i in range(m):\n",
    "            for j in range(n):\n",
    "                gamma[count, i, j] = Gamma(S[count], Strikes[i], r, Vol_surface[i, j], Maturities[j] - t)\n",
    "    return gamma\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the reward function in the following\n",
    "# buy, sell are of shape(N, m,n)\n",
    "# q is of shape(N, m, n)\n",
    "def reward(dt, A, B, gamma, net, T, S0, r, mu, sigma, Maturities, Strikes, q, buy, sell, Vol_surface):\n",
    "    N = int(T / dt)\n",
    "    m = A.shape[0]\n",
    "    n = A.shape[1]\n",
    "    S = Stock_Prices_Simulation(T, dt, mu, sigma, S0)\n",
    "    reward = torch.zeros(N)\n",
    "    for count in range(N):\n",
    "        t = torch.tensor([count * dt])\n",
    "        reward[count] = torch.tensor([0.0])\n",
    "        for i in range(m):\n",
    "            for j in range(n):\n",
    "                # declare a 2 dim tensor of shape (m,n)\n",
    "                x = torch.zeros(m, n)\n",
    "                x[i, j] = 1\n",
    "                reward[count] = reward[count] + (buy[count, i, j] * ((A[i,j] / (2 * B[i,j])) + 0.5 * (net.forward(t, q[count]) - net.forward(t, q[count] + x)))) * dt\n",
    "                reward[count] = reward[count] + (sell[count, i, j] * ((A[i,j] / (2 * B[i,j])) + 0.5 * (net.forward(t, q[count]) - net.forward(t, q[count] - x)))) * dt\n",
    "\n",
    "        reward[count] += torch.sum((Options_Theta(Vol_surface, S0, r, mu, sigma, T, dt, Maturities, Strikes)[count] + 0.5 * Options_Gamma(Vol_surface, S0, r, mu, sigma, T, dt, Maturities, Strikes)[count]) * q[count]) * dt\n",
    "        reward[count] = reward[count] - gamma * ((m * n * 1.79817986835) + torch.sum(torch.log(gamma / (2 * B)))) * dt\n",
    "    \n",
    "    return torch.sum(reward)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_data_collections(D, T, dt, A, B, gamma, net):\n",
    "    N = int(T / dt)\n",
    "    m = A.shape[0]\n",
    "    n = A.shape[1]\n",
    "    train_q = torch.zeros((D, N, m, n))\n",
    "    train_buy = torch.zeros((D, N, m, n))\n",
    "    train_sell = torch.zeros((D, N, m, n))\n",
    "    bid = torch.zeros((D, N, m, n))\n",
    "    ask = torch.zeros((D, N, m, n))\n",
    "    for count in range(D):\n",
    "        train_q[count], train_buy[count], train_sell[count], bid[count], ask[count] = Train_Data_Simulation(T, dt, A, B, gamma, net)\n",
    "    return train_q, train_buy, train_sell, bid, ask\n",
    "\n",
    "def train_stock(D, T, dt, mu, sigma, S0):\n",
    "    N = int(T / dt)\n",
    "    train_data = torch.zeros((D, N))\n",
    "    for count in range(D):\n",
    "        train_data[count] = Stock_Prices_Simulation(T, dt, mu, sigma, S0)\n",
    "    return train_data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.distributions as dist\n",
    "from torch.distributions.normal import Normal\n",
    "from torch.distributions.multivariate_normal import MultivariateNormal\n",
    "\n",
    "def kl_divergence(new_net, old_net, T, dt, A, B, gamma, q):\n",
    "    m = A.shape[0]\n",
    "    n = A.shape[1]\n",
    "    N = int(T / dt)\n",
    "    kl = torch.zeros(N)\n",
    "    old_mean = torch.zeros((N, 2 * m * n))\n",
    "    new_mean = torch.zeros((N, 2 * m * n))\n",
    "    cov = torch.zeros((N, 2 * m * n, 2 * m * n))\n",
    "    for count in range(N):\n",
    "        t = torch.tensor([count * dt])\n",
    "        for i in range(m):\n",
    "            for j in range(n):\n",
    "                # declare a 2 dim tensor of shape (m,n)\n",
    "                x = torch.zeros(m, n)\n",
    "                x[i, j] = 1\n",
    "                old_mean[count, i * n + j] = A[i, j] / (2 * B[i, j]) + 0.5 * (old_net.forward(t, q[count]) - old_net.forward(t, q[count] + x))\n",
    "                old_mean[count, i * n + j + 1] = A[i, j] / (2 * B[i, j]) + 0.5 * (old_net.forward(t, q[count]) - old_net.forward(t, q[count] - x))\n",
    "                new_mean[count, i * n + j] = A[i, j] / (2 * B[i, j]) + 0.5 * (new_net.forward(t, q[count]) - new_net.forward(t, q[count] + x))\n",
    "                new_mean[count, i * n + j + 1] = A[i, j] / (2 * B[i, j]) + 0.5 * (new_net.forward(t, q[count]) - new_net.forward(t, q[count] - x))\n",
    "                cov[count, i * n + j, i * n + j] = gamma / (2 * B[i, j])\n",
    "                cov[count, m * n + i * n + j, m * n + i * n + j] = gamma / (2 * B[i, j])\n",
    "\n",
    "        old_dist = MultivariateNormal(old_mean[count], cov[count])\n",
    "        new_dist = MultivariateNormal(new_mean[count], cov[count])\n",
    "        kl[count] = dist.kl_divergence(old_dist, new_dist)\n",
    "    return torch.sum(kl)\n",
    "\n",
    "\n",
    "\n",
    "# q, bid, ask is of shape (N, m,n)\n",
    "def normal_distribution_pdf(T, dt, A, B, gamma, net, q, bid, ask):\n",
    "    m = A.shape[0]\n",
    "    n = A.shape[1]\n",
    "    N = int(T / dt)\n",
    "    pdf_bid = torch.ones(N)\n",
    "    pdf_ask = torch.ones(N)\n",
    "    for count in range(N):\n",
    "        t = torch.tensor([count * dt])\n",
    "        for i in range(m):\n",
    "            for j in range(n):\n",
    "                # declare a 2 dim tensor of shape (m,n)\n",
    "                x = torch.zeros(m, n)\n",
    "                x[i, j] = 1\n",
    "                mean_bid = A[i, j] / (2 * B[i ,j]) + 0.5 * (net.forward(t, q[count]) - net.forward(t, q[count] + x))\n",
    "                mean_ask = A[i, j] / (2 * B[i ,j]) + 0.5 * (net.forward(t, q[count]) - net.forward(t, q[count] - x))\n",
    "                cov = gamma / (2 * B[i, j])\n",
    "                std = torch.sqrt(cov)\n",
    "                pdf_bid[count] = pdf_bid[count] * torch.exp(Normal(mean_bid, std).log_prob(bid[count, i, j]))\n",
    "                pdf_ask[count] = pdf_ask[count] * torch.exp(Normal(mean_ask, std).log_prob(ask[count, i, j]))\n",
    "\n",
    "    pdf = pdf_bid * pdf_ask\n",
    "    return pdf\n",
    "        \n",
    "    \n",
    "\n",
    "def total_loss(dt, A, B, gamma, new_net, old_net, T, S0, r, mu, sigma, Maturities, Strikes, Vol_surface, beta, train_q, train_buy, train_sell, bid, ask, D):\n",
    "    loss = torch.tensor([0.0])\n",
    "\n",
    "    for count in range(D):\n",
    "        pdf_new = normal_distribution_pdf(T, dt, A, B, gamma, new_net, train_q[count], bid[count], ask[count])\n",
    "        pdf_old = normal_distribution_pdf(T, dt, A, B, gamma, old_net, train_q[count], bid[count], ask[count])\n",
    "        loss = loss + reward(dt, A, B, gamma, old_net, T, S0, r, mu, sigma, Maturities, Strikes, train_q[count], train_buy[count], train_sell[count], Vol_surface) * torch.sum((pdf_new / pdf_old)[:-1])\n",
    "        loss = loss - beta * kl_divergence(new_net, old_net, T, dt, A, B, gamma, train_q[count])\n",
    "\n",
    "    return loss / D \n",
    "\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the reward function\n",
    "Vol_surface = torch.tensor([[0.2, 0.3], [0.4, 0.5]])\n",
    "S0 = 100\n",
    "r = 0.05\n",
    "T = 1\n",
    "dt = 0.01\n",
    "mu = 0.1\n",
    "sigma = 0.2\n",
    "gamma = 0.05\n",
    "Maturities = torch.tensor([3, 5])\n",
    "Strikes = torch.tensor([90, 110])\n",
    "net = MyNet(2, 2)\n",
    "learning_rate = 0.01\n",
    "num_epochs = 30\n",
    "A = torch.tensor([[1.0, 2.0], [3.0, 4.0]])\n",
    "B = torch.tensor([[0.2, 0.3], [0.2, 0.5]])\n",
    "learning_rate = 0.01\n",
    "num_epochs = 30\n",
    "D = 2\n",
    "\n",
    "beta = 0.1\n",
    "threshold = 0.01\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_net = MyNet(2, 2)\n",
    "old_net = MyNet(2, 2)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[125], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[39mprint\u001b[39m(i)\n\u001b[0;32m      4\u001b[0m old_net\u001b[39m.\u001b[39mload_state_dict(new_net\u001b[39m.\u001b[39mstate_dict())\n\u001b[1;32m----> 5\u001b[0m train_q, train_buy, train_sell, bid, ask \u001b[39m=\u001b[39m training_data_collections(D, T, dt, A, B, gamma, old_net)\n\u001b[0;32m      6\u001b[0m train_S \u001b[39m=\u001b[39m train_stock(D, T, dt, mu, sigma, S0)\n\u001b[0;32m      7\u001b[0m optimizer \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39moptim\u001b[39m.\u001b[39mAdam(new_net\u001b[39m.\u001b[39mparameters(), lr\u001b[39m=\u001b[39mlearning_rate)\n",
      "Cell \u001b[1;32mIn[110], line 11\u001b[0m, in \u001b[0;36mtraining_data_collections\u001b[1;34m(D, T, dt, A, B, gamma, net)\u001b[0m\n\u001b[0;32m      9\u001b[0m ask \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mzeros((D, N, m, n))\n\u001b[0;32m     10\u001b[0m \u001b[39mfor\u001b[39;00m count \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(D):\n\u001b[1;32m---> 11\u001b[0m     train_q[count], train_buy[count], train_sell[count], bid[count], ask[count] \u001b[39m=\u001b[39m Train_Data_Simulation(T, dt, A, B, gamma, net)\n\u001b[0;32m     12\u001b[0m \u001b[39mreturn\u001b[39;00m train_q, train_buy, train_sell, bid, ask\n",
      "Cell \u001b[1;32mIn[108], line 93\u001b[0m, in \u001b[0;36mTrain_Data_Simulation\u001b[1;34m(T, dt, A, B, gamma, net)\u001b[0m\n\u001b[0;32m     91\u001b[0m     orders \u001b[39m=\u001b[39m Market_Order_Simulation(dt, A, B, bid_matrix, ask_matrix)[\u001b[39m0\u001b[39m]\n\u001b[0;32m     92\u001b[0m     buy[count] \u001b[39m=\u001b[39m Market_Order_Simulation(dt, A, B, bid_matrix, ask_matrix)[\u001b[39m1\u001b[39m]\n\u001b[1;32m---> 93\u001b[0m     sell[count] \u001b[39m=\u001b[39m Market_Order_Simulation(dt, A, B, bid_matrix, ask_matrix)[\u001b[39m2\u001b[39m]\n\u001b[0;32m     94\u001b[0m     q[count \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m] \u001b[39m=\u001b[39m q[count] \u001b[39m+\u001b[39m orders\n\u001b[0;32m     96\u001b[0m \u001b[39mreturn\u001b[39;00m q, buy, sell, bid, ask\n",
      "Cell \u001b[1;32mIn[108], line 68\u001b[0m, in \u001b[0;36mMarket_Order_Simulation\u001b[1;34m(dt, A, B, bid_matrix, ask_matrix)\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[39mfor\u001b[39;00m j \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(n):\n\u001b[0;32m     67\u001b[0m     intensity_bid \u001b[39m=\u001b[39m A[i, j] \u001b[39m-\u001b[39m B[i, j] \u001b[39m*\u001b[39m bid_matrix[i, j]\n\u001b[1;32m---> 68\u001b[0m     intensity_ask \u001b[39m=\u001b[39m A[i, j] \u001b[39m-\u001b[39m B[i, j] \u001b[39m*\u001b[39m ask_matrix[i, j]\n\u001b[0;32m     69\u001b[0m     buy_orders[i, j] \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mpoisson(intensity_bid \u001b[39m*\u001b[39m dt)\n\u001b[0;32m     70\u001b[0m     sell_orders[i, j] \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mpoisson(intensity_ask \u001b[39m*\u001b[39m dt)\n",
      "File \u001b[1;32mc:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\lib\\site-packages\\torch\\fx\\traceback.py:57\u001b[0m, in \u001b[0;36mformat_stack\u001b[1;34m()\u001b[0m\n\u001b[0;32m     54\u001b[0m     \u001b[39mreturn\u001b[39;00m current_stack\u001b[39m.\u001b[39mcopy()\n\u001b[0;32m     55\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     56\u001b[0m     \u001b[39m# fallback to traceback.format_stack()\u001b[39;00m\n\u001b[1;32m---> 57\u001b[0m     \u001b[39mreturn\u001b[39;00m traceback\u001b[39m.\u001b[39;49mformat_stack()\n",
      "File \u001b[1;32mc:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\lib\\traceback.py:197\u001b[0m, in \u001b[0;36mformat_stack\u001b[1;34m(f, limit)\u001b[0m\n\u001b[0;32m    195\u001b[0m \u001b[39mif\u001b[39;00m f \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    196\u001b[0m     f \u001b[39m=\u001b[39m sys\u001b[39m.\u001b[39m_getframe()\u001b[39m.\u001b[39mf_back\n\u001b[1;32m--> 197\u001b[0m \u001b[39mreturn\u001b[39;00m format_list(extract_stack(f, limit\u001b[39m=\u001b[39;49mlimit))\n",
      "File \u001b[1;32mc:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\lib\\traceback.py:211\u001b[0m, in \u001b[0;36mextract_stack\u001b[1;34m(f, limit)\u001b[0m\n\u001b[0;32m    209\u001b[0m \u001b[39mif\u001b[39;00m f \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    210\u001b[0m     f \u001b[39m=\u001b[39m sys\u001b[39m.\u001b[39m_getframe()\u001b[39m.\u001b[39mf_back\n\u001b[1;32m--> 211\u001b[0m stack \u001b[39m=\u001b[39m StackSummary\u001b[39m.\u001b[39;49mextract(walk_stack(f), limit\u001b[39m=\u001b[39;49mlimit)\n\u001b[0;32m    212\u001b[0m stack\u001b[39m.\u001b[39mreverse()\n\u001b[0;32m    213\u001b[0m \u001b[39mreturn\u001b[39;00m stack\n",
      "File \u001b[1;32mc:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\lib\\traceback.py:362\u001b[0m, in \u001b[0;36mStackSummary.extract\u001b[1;34m(klass, frame_gen, limit, lookup_lines, capture_locals)\u001b[0m\n\u001b[0;32m    359\u001b[0m     result\u001b[39m.\u001b[39mappend(FrameSummary(\n\u001b[0;32m    360\u001b[0m         filename, lineno, name, lookup_line\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, \u001b[39mlocals\u001b[39m\u001b[39m=\u001b[39mf_locals))\n\u001b[0;32m    361\u001b[0m \u001b[39mfor\u001b[39;00m filename \u001b[39min\u001b[39;00m fnames:\n\u001b[1;32m--> 362\u001b[0m     linecache\u001b[39m.\u001b[39;49mcheckcache(filename)\n\u001b[0;32m    363\u001b[0m \u001b[39m# If immediate lookup was desired, trigger lookups now.\u001b[39;00m\n\u001b[0;32m    364\u001b[0m \u001b[39mif\u001b[39;00m lookup_lines:\n",
      "File \u001b[1;32mc:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\lib\\linecache.py:72\u001b[0m, in \u001b[0;36mcheckcache\u001b[1;34m(filename)\u001b[0m\n\u001b[0;32m     70\u001b[0m     \u001b[39mcontinue\u001b[39;00m   \u001b[39m# no-op for files loaded via a __loader__\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 72\u001b[0m     stat \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39;49mstat(fullname)\n\u001b[0;32m     73\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mOSError\u001b[39;00m:\n\u001b[0;32m     74\u001b[0m     cache\u001b[39m.\u001b[39mpop(filename, \u001b[39mNone\u001b[39;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(num_epochs):\n",
    "    torch.autograd.set_detect_anomaly(True)\n",
    "    print(i)\n",
    "    old_net.load_state_dict(new_net.state_dict())\n",
    "    train_q, train_buy, train_sell, bid, ask = training_data_collections(D, T, dt, A, B, gamma, old_net)\n",
    "    train_S = train_stock(D, T, dt, mu, sigma, S0)\n",
    "    optimizer = torch.optim.Adam(new_net.parameters(), lr=learning_rate)\n",
    "    optimizer.zero_grad()\n",
    "    loss = total_loss(dt, A, B, gamma, new_net, old_net, T, S0, r, mu, sigma, Maturities, Strikes, Vol_surface, beta, train_q, train_buy, train_sell, bid, ask, D)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    \n",
    "    if kl_divergence(new_net, old_net, T, dt, A, B, gamma, train_q) > 1.5 * threshold:\n",
    "        beta = beta * 2\n",
    "    elif kl_divergence(new_net, old_net, T, dt, A, B, gamma, train_q) < threshold / 1.5:\n",
    "        beta = beta / 2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.autograd.anomaly_mode.set_detect_anomaly at 0x1f1f1a16dc0>"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.autograd.set_detect_anomaly(True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qids-2023-comp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
