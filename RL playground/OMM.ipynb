{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import scipy.stats as scistat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock_Conv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(ResidualBlock_Conv, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv1d(in_channels, out_channels, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.conv2 = nn.Conv1d(out_channels, out_channels, kernel_size=3, stride=1, padding=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv2(out)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "class ResNet_Conv(nn.Module):\n",
    "    def __init__(self, m, n, output_size, input_channels, output_channels, num_blocks, final_act):\n",
    "        super(ResNet_Conv, self).__init__()\n",
    "\n",
    "        self.fc = nn.Linear(1 + m * n, 1024)\n",
    "        self.conv1 = nn.Conv1d(input_channels, output_channels, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.final_act = final_act\n",
    "\n",
    "        self.blocks = nn.ModuleList()\n",
    "        for _ in range(num_blocks):\n",
    "            self.blocks.append(ResidualBlock_Conv(output_channels, output_channels))\n",
    "\n",
    "        self.conv2 = nn.Conv1d(output_channels, input_channels, kernel_size=3, stride=1, padding=1)\n",
    "        self.fc2 = nn.Linear(1024, 512)\n",
    "        self.fc3 = nn.Linear(512, 256)\n",
    "        self.fc4 = nn.Linear(256, 256)\n",
    "        self.fc5 = nn.Linear(256, output_size)\n",
    "\n",
    "    def forward(self, t, q):\n",
    "        q = q.view(-1)\n",
    "        x = torch.cat((t, q), dim=0)\n",
    "        out = self.fc(x)\n",
    "        out = out.unsqueeze(0)\n",
    "        out = out.unsqueeze(0)\n",
    "        out = self.conv1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        for block in self.blocks:\n",
    "            out = block(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.relu(out)\n",
    "        out = out.squeeze()\n",
    "        out = self.fc2(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc3(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc4(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc5(out)\n",
    "        out = 0.1 * self.final_act(out)\n",
    "\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this Gaussian policy implementation is for the actor-critic algorithm\n",
    "# modeling the mean of bid-ask policy as a neural network directly\n",
    "def Gaussian_Policy(net, t, q, A, B, gamma):\n",
    "    number = A.shape[0] * A.shape[1]\n",
    "    mean = net.forward(t, q) # the output for the neural network is of dim 2*m*n\n",
    "    bid_mean = mean[:number]\n",
    "    ask_mean = mean[number:]\n",
    "    variance = (gamma / (2 * B)).view(-1)\n",
    "    std = torch.sqrt(variance)\n",
    "    bid_matrix = torch.normal(bid_mean, std).view(A.shape)\n",
    "    ask_matrix = torch.normal(ask_mean, std).view(A.shape)\n",
    "\n",
    "    return bid_matrix, ask_matrix\n",
    "\n",
    "\n",
    "def Stock_Prices_Simulation(T, dt, mu, sigma, S0):\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    N = int(T / dt)\n",
    "    S = torch.zeros(N).to(device)\n",
    "    S[0] = S0\n",
    "    for count in range(N - 1):\n",
    "        S[count + 1] = S[count] + mu * S[count] * dt + sigma * S[count] * torch.sqrt(dt) * torch.normal(0.0, 1.0, size=(1,)).to(device)\n",
    "    return S\n",
    "\n",
    "\n",
    "def Market_Order_Simulation(dt, A, B, bid_matrix, ask_matrix):\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    orders = torch.zeros(bid_matrix.shape).to(device)\n",
    "    buy_orders = torch.zeros(bid_matrix.shape).to(device)\n",
    "    sell_orders = torch.zeros(bid_matrix.shape).to(device)\n",
    "    m = bid_matrix.shape[0]\n",
    "    n = bid_matrix.shape[1]\n",
    "    for i in range(m):\n",
    "        for j in range(n):\n",
    "            intensity_bid = A[i, j] - B[i, j] * bid_matrix[i, j]\n",
    "            intensity_ask = A[i, j] - B[i, j] * ask_matrix[i, j]\n",
    "            buy_orders[i, j] = torch.poisson(intensity_bid * dt)\n",
    "            sell_orders[i, j] = torch.poisson(intensity_ask * dt)\n",
    "            orders[i, j] = buy_orders[i, j] - sell_orders[i, j]\n",
    "\n",
    "    return orders, buy_orders, sell_orders\n",
    "    \n",
    "\n",
    "def Train_Data_Simulation(T, dt, A, B, gamma, net):\n",
    "    \n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    N = int(T / dt)\n",
    "    m = A.shape[0]\n",
    "    n = A.shape[1]\n",
    "    q = torch.zeros((N, m, n)).to(device)\n",
    "    buy = torch.zeros((N, m, n)).to(device)\n",
    "    sell = torch.zeros((N, m, n)).to(device)\n",
    "    bid = torch.zeros((N, m, n)).to(device)\n",
    "    ask = torch.zeros((N, m, n)).to(device)\n",
    "\n",
    "    for count in range(N - 1):\n",
    "        t = count * dt\n",
    "        bid_matrix, ask_matrix = Gaussian_Policy(net, t, q[count], A, B, gamma)\n",
    "        orders, buy_orders, sell_orders = Market_Order_Simulation(dt, A, B, bid_matrix, ask_matrix)\n",
    "        buy[count] = buy_orders\n",
    "        sell[count] = sell_orders\n",
    "        q[count + 1] = q[count] + orders\n",
    "        bid[count] = bid_matrix\n",
    "        ask[count] = ask_matrix\n",
    "    \n",
    "    return q, buy, sell, bid, ask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reward(q, buy, sell, S, r, T, dt, Maturities, Strikes, Vol_surface, Policy_Net, gamma, B, Value_Net):\n",
    "    N = int(T / dt)\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    m = Vol_surface.shape[0]\n",
    "    n = Vol_surface.shape[1]\n",
    "    reward = torch.zeros(N).to(device)\n",
    "    Opt_Theta = Options_Theta(Vol_surface, S, r, T, dt, Maturities, Strikes)\n",
    "    Opt_Gamma = Options_Gamma(Vol_surface, S, r, T, dt, Maturities, Strikes)\n",
    "    for count in range(N - 1):\n",
    "        t = count * dt\n",
    "        mean = Policy_Net(t, q[count])\n",
    "        profit = torch.sum(buy[count] * (mean[ : m*n].view(Vol_surface.shape)) + sell[count] * (mean[m*n :].view(Vol_surface.shape)))\n",
    "        Theta = Opt_Theta[count] * q[count] * dt\n",
    "        Gamma = 0.5 * Opt_Gamma[count] * q[count] * dt\n",
    "        reward[count] = profit + torch.sum(Theta) + torch.sum(Gamma) - gamma * ((m * n * 1.79817986835) + torch.sum(torch.log(gamma / (2 * B))))\n",
    "        td_error = Value_Net(t + dt, q[count + 1]) - Value_Net(t, q[count])\n",
    "        reward[count] += td_error.view(reward[count].shape)\n",
    "\n",
    "    return reward\n",
    "\n",
    "\n",
    "def critic_loss(q, buy, sell, S, r, T, dt, Maturities, Strikes, Vol_surface, Policy_Net, gamma, B, Value_Net):\n",
    "    N = int(T / dt)\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    m = Vol_surface.shape[0]\n",
    "    n = Vol_surface.shape[1]\n",
    "    r = reward(q, buy, sell, S, r, T, dt, Maturities, Strikes, Vol_surface, Policy_Net, gamma, B, Value_Net)\n",
    "    loss = 0.5 * torch.sum(r ** 2)\n",
    "    return loss\n",
    "\n",
    "\n",
    "def probability(Policy_Net, q, T, dt, bid, ask, B, gamma):\n",
    "    N = int(T / dt)\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    m = bid.shape[0]\n",
    "    n = bid.shape[1]\n",
    "    prob = torch.zeros(N).to(device)\n",
    "    for count in range(N - 1):\n",
    "        t = count * dt\n",
    "        mean = Policy_Net(t, q[count])\n",
    "        bid_matrix = bid[count].view(-1)\n",
    "        ask_matrix = ask[count].view(-1)\n",
    "        bid_ask_matrix = torch.cat((bid_matrix, ask_matrix), 0)\n",
    "        diag = torch.cat((gamma / (2 * B.view(-1)), gamma / (2 * B.view(-1))), 0)\n",
    "        cov = torch.diag(diag)\n",
    "        prob[count] = torch.distributions.multivariate_normal.MultivariateNormal(mean, cov).log_prob(bid_ask_matrix)\n",
    "\n",
    "    return prob\n",
    "\n",
    "\n",
    "def actor_loss(Policy_Net, q, T, dt, bid, ask, B, gamma, buy, sell, S, r, Maturities, Strikes, Vol_surface, Value_Net):\n",
    "    prob = probability(Policy_Net, q, T, dt, bid, ask, B, gamma)\n",
    "    r = reward(q, buy, sell, S, r, T, dt, Maturities, Strikes, Vol_surface, Policy_Net, gamma, B, Value_Net)\n",
    "    loss = -torch.sum(prob * r)\n",
    "    return loss\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "A = torch.tensor([[36, 34, 32, 30], [46, 44, 42, 40], [56, 54, 52, 50], [46, 44, 42, 40], [36, 34, 32, 30]]).to(device)\n",
    "B = torch.tensor([[3, 3, 3, 3], [4, 4, 4, 4], [5, 5, 5, 5], [4, 4, 4, 4], [3, 3, 3, 3]]).to(device)\n",
    "gamma = torch.tensor([0.1]).to(device)\n",
    "T = torch.tensor([1]).to(device)\n",
    "dt = torch.tensor([0.01]).to(device)\n",
    "mu = torch.tensor([0.01]).to(device)\n",
    "sigma = torch.tensor([0.05]).to(device)\n",
    "S0 = torch.tensor([100]).to(device)\n",
    "S = Stock_Prices_Simulation(T, dt, mu, sigma, S0)\n",
    "m = 5\n",
    "n = 4\n",
    "q = torch.zeros(m, n).to(device)\n",
    "Vol_surface = torch.tensor([[0.2, 0.2, 0.18, 0.18], [0.14, 0.14, 0.12, 0.12], [0.1, 0.1, 0.08, 0.08], [0.14, 0.14, 0.12, 0.12], [0.2, 0.2, 0.18, 0.18]]).to(device)\n",
    "Strikes = torch.tensor([90, 95, 100, 105, 110]).to(device) # means i in the code\n",
    "Maturities = torch.tensor([2, 3, 4, 5]).to(device) # means j in the code\n",
    "r = torch.tensor([0]).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# call option price function with S, K, T, r, sigma\n",
    "def call_option_price(S, K, T, r, sigma):\n",
    "    d1 = (torch.log(S / K) + (r + 0.5 * sigma ** 2) * T) / (sigma * torch.sqrt(T))\n",
    "    d2 = d1 - sigma * torch.sqrt(T)\n",
    "    return S * torch.distributions.normal.Normal(0, 1).cdf(d1) - K * torch.exp(-r * T) * torch.distributions.normal.Normal(0, 1).cdf(d2)\n",
    "\n",
    "\n",
    "def final_return(buy, sell, bid, ask, T, dt):\n",
    "    N = int(T / dt)\n",
    "    profit = 0\n",
    "    for count in range(N - 1):\n",
    "        profit += torch.sum(buy[count] * bid[count] + sell[count] * ask[count])\n",
    "\n",
    "    return profit.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy_net = ResNet_Conv(m, n, 2 * m * n, 1, 1, 2, nn.Sigmoid()).to(device)\n",
    "value_net = ResNet_Conv(m, n, 1, 1, 1, 2, nn.Sigmoid()).to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(policy_net.parameters(), lr=0.001)\n",
    "optimizer_value = torch.optim.Adam(value_net.parameters(), lr=0.001)\n",
    "\n",
    "V = []\n",
    "P = []\n",
    "\n",
    "for epoch in range(100):\n",
    "    optimizer.zero_grad()\n",
    "    optimizer_value.zero_grad()\n",
    "    S = Stock_Prices_Simulation(T, dt, mu, sigma, S0)\n",
    "    q, buy, sell, bid, ask = Train_Data_Simulation(T, dt, A, B, gamma, policy_net)\n",
    "    p_loss = actor_loss(policy_net, q, T, dt, bid, ask, B, gamma, buy, sell, S, r, Maturities, Strikes, Vol_surface, value_net)\n",
    "    v_loss = critic_loss(q, buy, sell, S, r, T, dt, Maturities, Strikes, Vol_surface, policy_net, gamma, B, value_net)\n",
    "    p_loss.backward()\n",
    "    v_loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer_value.step()\n",
    "    print(p_loss.item())\n",
    "    print(v_loss.item())    \n",
    "    V.append(v_loss.item())\n",
    "    P.append(p_loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_returns = []\n",
    "for count in range(100):\n",
    "    q, buy, sell, bid, ask = Train_Data_Simulation(T, dt, A, B, gamma, policy_net)\n",
    "    final_returns.append(final_return(buy, sell, bid, ask, T, dt))\n",
    "    print(q)\n",
    "\n",
    "print(final_returns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "q1 = torch.tensor([[0, 0, 0, 0], [0, 0, 0, 0], [0, 0, 0, 0], [0, 0, 0, 0], [0, 0, 0, 0]]).to(device)\n",
    "q2 = torch.tensor([[3 * abs(2 - i) + j for j in range(4)] for i in range(5)]).to(device)\n",
    "q3 = torch.tensor([[3, 4, -5, -6], [1, 2, -3, -4], [0, 1, -1, 1], [1, -2, 3, 4], [2, -3, 4, 5]]).to(device)\n",
    "inventory = torch.zeros(3, 5, 4).to(device)\n",
    "inventory[0] = q1\n",
    "inventory[1] = q2\n",
    "inventory[2] = q3\n",
    "\n",
    "print(inventory)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pvlib",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
