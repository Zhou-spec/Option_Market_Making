{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "def loc(nb):\n",
    "    cells = load(open(nb))['cells']\n",
    "    return sum(len(c['source']) for c in cells if c['cell_type'] == 'code')\n",
    "\n",
    "def run(ipynb_files):\n",
    "    return sum(loc(nb) for nb in ipynb_files)\n",
    "\n",
    "# the following neural network is to model the value function\n",
    "class MyNet(nn.Module):\n",
    "    def __init__(self, m, n):\n",
    "        super(MyNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(1 + m * n, 64)\n",
    "        self.fc2 = nn.Linear(64, 32)\n",
    "        self.fc3 = nn.Linear(32, 1)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "# x is 2 dim torch tensor with shape (m, n)\n",
    "    def forward(self, t, x):\n",
    "        #make x 1 dim\n",
    "        x = x.view(-1)\n",
    "        x = torch.cat((t, x), dim=0)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "    \n",
    "# The Gaussian policy returns torch tensor with shape (m, n)\n",
    "def Gaussian_Policy(net, t, q, A, B, gamma):\n",
    "    \n",
    "    bid_matrix  = torch.zeros(q.shape)\n",
    "    ask_matrix  = torch.zeros(q.shape)\n",
    "\n",
    "    for i in range(A.shape[0]):\n",
    "        for j in range(A.shape[1]):\n",
    "            x = torch.zeros(q.shape)\n",
    "            x[i, j] = 1\n",
    "            mean_bid = A[i, j] / (2 * B[i, j]) + 0.5 * (net.forward(t, q) - net.forward(t, q + x))\n",
    "            mean_ask = A[i, j] / (2 * B[i, j]) + 0.5 * (net.forward(t, q) - net.forward(t, q - x))\n",
    "            variance = gamma / (2 * B[i, j])\n",
    "            std = torch.sqrt(variance)\n",
    "            bid_matrix[i, j] = torch.normal(mean_bid, std)\n",
    "            ask_matrix[i, j] = torch.normal(mean_ask, std)\n",
    "\n",
    "    return bid_matrix, ask_matrix\n",
    "    \n",
    "\n",
    "import math\n",
    "import scipy.stats as scistat\n",
    "\n",
    "def Market_Order_Simulation(dt, A, B, bid_matrix, ask_matrix):\n",
    "    orders = torch.zeros(bid_matrix.shape)\n",
    "    buy_orders = torch.zeros(bid_matrix.shape)\n",
    "    sell_orders = torch.zeros(bid_matrix.shape)\n",
    "    m = bid_matrix.shape[0]\n",
    "    n = bid_matrix.shape[1]\n",
    "    for i in range(m):\n",
    "        for j in range(n):\n",
    "            intensity_bid = A[i, j] - B[i, j] * bid_matrix[i, j]\n",
    "            intensity_ask = A[i, j] - B[i, j] * ask_matrix[i, j]\n",
    "            buy_orders[i, j] = torch.poisson(intensity_bid * dt)\n",
    "            sell_orders[i, j] = torch.poisson(intensity_ask * dt)\n",
    "            orders[i, j] = buy_orders[i, j] - sell_orders[i, j]\n",
    "\n",
    "    return [orders, buy_orders, sell_orders]\n",
    "\n",
    "# this function returns the inventory path\n",
    "def Train_Data_Simulation(T, dt, A, B, gamma, net):\n",
    "    N = int(T / dt)\n",
    "    m = A.shape[0]\n",
    "    n = A.shape[1]\n",
    "    q = torch.zeros((N, m, n))\n",
    "    buy = torch.zeros((N, m, n))\n",
    "    sell = torch.zeros((N, m, n))\n",
    "\n",
    "    for count in range(N - 1):\n",
    "        t = torch.Tensor([count * dt])\n",
    "        bid_matrix, ask_matrix = Gaussian_Policy(net, t, q[count], A, B, gamma)\n",
    "        orders = Market_Order_Simulation(dt, A, B, bid_matrix, ask_matrix)[0]\n",
    "        buy[count] = Market_Order_Simulation(dt, A, B, bid_matrix, ask_matrix)[1]\n",
    "        sell[count] = Market_Order_Simulation(dt, A, B, bid_matrix, ask_matrix)[2]\n",
    "        q[count + 1] = q[count] + orders\n",
    "    \n",
    "    return q, buy, sell\n",
    "\n",
    "# this function returns the stock prices path\n",
    "def Stock_Prices_Simulation(T, dt, mu, sigma, S0):\n",
    "    N = int(T / dt)\n",
    "    S = torch.zeros(N)\n",
    "    S[0] = S0\n",
    "    for count in range(N - 1):\n",
    "        S[count + 1] = S[count] + mu * S[count] * dt + sigma * S[count] * math.sqrt(dt) * torch.normal(0.0, 1.0, size=(1,))\n",
    "    return S\n",
    "\n",
    "\n",
    "#the following are option greeks' functions\n",
    "def d1(S, K, r, sigma, T):\n",
    "    return (np.log(S/K) + (r+sigma*sigma/2)*T)/(sigma*np.sqrt(T))\n",
    "\n",
    "def d2(S, K, r, sigma, T):\n",
    "    return d1(S, K, r, sigma, T) - sigma*np.sqrt(T)\n",
    "\n",
    "def Gamma(S, K, r, sigma, T):\n",
    "    return scistat.norm.pdf(d1(S, K, r, sigma, T))/(S*sigma*np.sqrt(T))\n",
    "\n",
    "def Theta(S, K, r, sigma, T):\n",
    "    aux1 = -S*scistat.norm.pdf(d1(S, K, r, sigma, T))*sigma/(2*np.sqrt(T))\n",
    "    aux2 = -r*K*np.exp(-r*T)*scistat.norm.cdf(d2(S, K, r, sigma, T))\n",
    "    return aux1+aux2\n",
    "\n",
    "\n",
    "def Options_Theta(Vol_surface, S0, r, mu, sigma, T, dt, Maturities, Strikes):\n",
    "    N = int(T / dt)\n",
    "    m = Vol_surface.shape[0]\n",
    "    n = Vol_surface.shape[1]\n",
    "    theta = torch.zeros((N, m, n))\n",
    "    S = Stock_Prices_Simulation(T, dt, mu, sigma, S0)\n",
    "    for count in range(N):\n",
    "        t = count * dt\n",
    "        for i in range(m):\n",
    "            for j in range(n):\n",
    "                theta[count, i, j] = Theta(S[count], Strikes[i], r, Vol_surface[i, j], Maturities[j] - t)\n",
    "    return theta\n",
    "\n",
    "\n",
    "def Options_Gamma(Vol_surface, S0, r, mu, sigma, T, dt, Maturities, Strikes):\n",
    "    N = int(T / dt)\n",
    "    m = Vol_surface.shape[0]\n",
    "    n = Vol_surface.shape[1]\n",
    "    gamma = torch.zeros((N, m, n))\n",
    "    S = Stock_Prices_Simulation(T, dt, mu, sigma, S0)\n",
    "    for count in range(N):\n",
    "        t = count * dt\n",
    "        for i in range(m):\n",
    "            for j in range(n):\n",
    "                gamma[count, i, j] = Gamma(S[count], Strikes[i], r, Vol_surface[i, j], Maturities[j] - t)\n",
    "    return gamma\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the reward function in the following\n",
    "# buy, sell are of shape(N, m,n)\n",
    "# q is of shape(N, m, n)\n",
    "def reward(dt, A, B, gamma, net, T, S0, r, mu, sigma, Maturities, Strikes, q, buy, sell, Vol_surface):\n",
    "    N = int(T / dt)\n",
    "    m = A.shape[0]\n",
    "    n = A.shape[1]\n",
    "    S = Stock_Prices_Simulation(T, dt, mu, sigma, S0)\n",
    "    reward = torch.zeros(N)\n",
    "    for count in range(N):\n",
    "        t = torch.tensor([count * dt])\n",
    "        reward[count] = torch.tensor([0.0])\n",
    "        for i in range(m):\n",
    "            for j in range(n):\n",
    "                # declare a 2 dim tensor of shape (m,n)\n",
    "                x = torch.zeros(m, n)\n",
    "                x[i, j] = 1\n",
    "                reward[count] = reward[count] + (buy[count, i, j] * ((A[i,j] / (2 * B[i,j])) + 0.5 * (net.forward(t, q[count]) - net.forward(t, q[count] + x)))) * dt\n",
    "                reward[count] = reward[count] + (sell[count, i, j] * ((A[i,j] / (2 * B[i,j])) + 0.5 * (net.forward(t, q[count]) - net.forward(t, q[count] - x)))) * dt\n",
    "\n",
    "        reward[count] += torch.sum((Options_Theta(Vol_surface, S0, r, mu, sigma, T, dt, Maturities, Strikes)[count] + 0.5 * Options_Gamma(Vol_surface, S0, r, mu, sigma, T, dt, Maturities, Strikes)[count]) * q[count]) * dt\n",
    "        reward[count] = reward[count] - gamma * ((m * n * 1.79817986835) + torch.sum(torch.log(gamma / (2 * B)))) * dt\n",
    "    \n",
    "    return torch.sum(reward)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the reward function\n",
    "Vol_surface = torch.tensor([[0.2, 0.3], [0.4, 0.5]])\n",
    "S0 = 100\n",
    "r = 0.05\n",
    "T = 1\n",
    "dt = 0.01\n",
    "mu = 0.1\n",
    "sigma = 0.2\n",
    "gamma = 0.05\n",
    "Maturities = torch.tensor([3, 5])\n",
    "Strikes = torch.tensor([90, 110])\n",
    "net = MyNet(2, 2)\n",
    "learning_rate = 0.01\n",
    "num_epochs = 30\n",
    "A = torch.tensor([[1.0, 2.0], [3.0, 4.0]])\n",
    "B = torch.tensor([[0.2, 0.3], [0.2, 0.5]])\n",
    "learning_rate = 0.01\n",
    "num_epochs = 30\n",
    "D = 10\n",
    "\n",
    "S = Stock_Prices_Simulation(T, dt, mu, sigma, S0)\n",
    "q, buy, sell = Train_Data_Simulation(T, dt, A, B, gamma, net)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_data_collections(D, T, dt, A, B, gamma, net):\n",
    "    N = int(T / dt)\n",
    "    m = A.shape[0]\n",
    "    n = A.shape[1]\n",
    "    train_q = torch.zeros((D, N, m, n))\n",
    "    train_buy = torch.zeros((D, N, m, n))\n",
    "    train_sell = torch.zeros((D, N, m, n))\n",
    "    for count in range(D):\n",
    "        train_q[count], train_buy[count], train_sell[count] = Train_Data_Simulation(T, dt, A, B, gamma, net)\n",
    "    return train_q, train_buy, train_sell\n",
    "\n",
    "def train_stock(D, T, dt, mu, sigma, S0):\n",
    "    N = int(T / dt)\n",
    "    train_data = torch.zeros((D, N))\n",
    "    for count in range(D):\n",
    "        train_data[count] = Stock_Prices_Simulation(T, dt, mu, sigma, S0)\n",
    "    return train_data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.distributions as dist\n",
    "\n",
    "def kl_divergence(mu1, cov1, mu2, cov2):\n",
    "    dist1 = dist.multivariate_normal.MultivariateNormal(mu1, cov1)\n",
    "    dist2 = dist.multivariate_normal.MultivariateNormal(mu2, cov2)\n",
    "    \n",
    "    kl = dist.kl.kl_divergence(dist1, dist2)\n",
    "    \n",
    "    return kl.item()  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '--ip=127.0.0.1'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m train_q, train_buy, train_sell \u001b[39m=\u001b[39m training_data_collections(D, T, dt, A, B, gamma, net)\n\u001b[0;32m      2\u001b[0m train_S \u001b[39m=\u001b[39m train_stock(D, T, dt, mu, sigma, S0)\n\u001b[1;32m----> 4\u001b[0m \u001b[39mprint\u001b[39m(run(argv[\u001b[39m1\u001b[39;49m:]))\n",
      "Cell \u001b[1;32mIn[16], line 15\u001b[0m, in \u001b[0;36mrun\u001b[1;34m(ipynb_files)\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrun\u001b[39m(ipynb_files):\n\u001b[1;32m---> 15\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msum\u001b[39;49m(loc(nb) \u001b[39mfor\u001b[39;49;00m nb \u001b[39min\u001b[39;49;00m ipynb_files)\n",
      "Cell \u001b[1;32mIn[16], line 15\u001b[0m, in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrun\u001b[39m(ipynb_files):\n\u001b[1;32m---> 15\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msum\u001b[39m(loc(nb) \u001b[39mfor\u001b[39;00m nb \u001b[39min\u001b[39;00m ipynb_files)\n",
      "Cell \u001b[1;32mIn[16], line 11\u001b[0m, in \u001b[0;36mloc\u001b[1;34m(nb)\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mloc\u001b[39m(nb):\n\u001b[1;32m---> 11\u001b[0m     cells \u001b[39m=\u001b[39m load(\u001b[39mopen\u001b[39;49m(nb))[\u001b[39m'\u001b[39m\u001b[39mcells\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m     12\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msum\u001b[39m(\u001b[39mlen\u001b[39m(c[\u001b[39m'\u001b[39m\u001b[39msource\u001b[39m\u001b[39m'\u001b[39m]) \u001b[39mfor\u001b[39;00m c \u001b[39min\u001b[39;00m cells \u001b[39mif\u001b[39;00m c[\u001b[39m'\u001b[39m\u001b[39mcell_type\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mcode\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\lib\\site-packages\\IPython\\core\\interactiveshell.py:282\u001b[0m, in \u001b[0;36m_modified_open\u001b[1;34m(file, *args, **kwargs)\u001b[0m\n\u001b[0;32m    275\u001b[0m \u001b[39mif\u001b[39;00m file \u001b[39min\u001b[39;00m {\u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m}:\n\u001b[0;32m    276\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    277\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mIPython won\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt let you open fd=\u001b[39m\u001b[39m{\u001b[39;00mfile\u001b[39m}\u001b[39;00m\u001b[39m by default \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    278\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    279\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39myou can use builtins\u001b[39m\u001b[39m'\u001b[39m\u001b[39m open.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    280\u001b[0m     )\n\u001b[1;32m--> 282\u001b[0m \u001b[39mreturn\u001b[39;00m io_open(file, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '--ip=127.0.0.1'"
     ]
    }
   ],
   "source": [
    "train_q, train_buy, train_sell = training_data_collections(D, T, dt, A, B, gamma, net)\n",
    "train_S = train_stock(D, T, dt, mu, sigma, S0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_net = MyNet(2, 2)\n",
    "old_net = MyNet(2, 2)\n",
    "\n",
    "for i in range(num_epochs):\n",
    "    old_net.load_state_dict(new_net.state_dict())\n",
    "    train_q, train_buy, train_sell = training_data_collections(D, T, dt, A, B, gamma, old_net)\n",
    "    train_S = train_stock(D, T, dt, mu, sigma, S0)\n",
    "    optimizer = torch.optim.Adam(new_net.parameters(), lr = learning_rate)\n",
    "    for j in range(D):\n",
    "        q = train_q[j]\n",
    "        buy = train_buy[j]\n",
    "        sell = train_sell[j]\n",
    "        S = train_S[j]\n",
    "        \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0012, 0.0012, 0.0012, 0.0012, 0.0609, 0.0620, 0.0999, 0.0647, 0.0642,\n",
       "        0.0622, 0.0623, 0.1369, 0.0622, 0.0650, 0.0622, 0.0606, 0.0582, 0.0678,\n",
       "        0.0130, 0.1368, 0.0694, 0.0628, 0.0621, 0.0600, 0.0630, 0.0540, 0.0744,\n",
       "        0.0614, 0.1035, 0.0649, 0.1078, 0.0686, 0.0977, 0.0683, 0.0690, 0.0563,\n",
       "        0.0727, 0.0740, 0.0716, 0.0701, 0.0619, 0.0678, 0.0644, 0.0748, 0.1498,\n",
       "        0.1048, 0.0492, 0.0649, 0.0677, 0.0597, 0.1385, 0.0686, 0.1378, 0.1493,\n",
       "        0.1269, 0.1510, 0.1287, 0.1476, 0.2207, 0.1324, 0.1462, 0.1575, 0.1467,\n",
       "        0.1530, 0.1326, 0.1208, 0.1343, 0.1468, 0.1475, 0.1924, 0.1953, 0.1988,\n",
       "        0.1930, 0.2037, 0.2054, 0.2048, 0.1025, 0.2054, 0.1727, 0.2047, 0.1714,\n",
       "        0.1822, 0.2049, 0.1780, 0.1672, 0.2078, 0.1365, 0.1987, 0.1740, 0.1543,\n",
       "        0.1819, 0.1909, 0.1915, 0.1832, 0.2110, 0.1970, 0.2097, 0.1993, 0.1999,\n",
       "        0.2142], grad_fn=<CopySlices>)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reward(dt, A, B, gamma, net, T, S0, r, mu, sigma, Maturities, Strikes, q, buy, sell, Vol_surface)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate the PPO algorithm\n",
    "\n",
    "# define the PPO algorithm\n",
    "def PPO(dt, A, B, gamma, net, T, S0, r, mu, sigma, Maturities, Strikes, Vol_surface, learning_rate, num_epochs):\n",
    "    N = int(T / dt)\n",
    "    m = A.shape[0]\n",
    "    n = A.shape[1]\n",
    "    S = Stock_Prices_Simulation(T, dt, mu, sigma, S0)\n",
    "    q, buy, sell = Train_Data_Simulation(T, dt, A, B, gamma, net)\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate)\n",
    "    for epoch in range(num_epochs):\n",
    "        # forward pass\n",
    "        reward_sum = reward(dt, A, B, gamma, net, T, S0, r, mu, sigma, Maturities, Strikes, q, buy, sell, Vol_surface)\n",
    "        # backward pass\n",
    "        optimizer.zero_grad()\n",
    "        reward_sum.backward()\n",
    "        optimizer.step()\n",
    "    return net\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qids-2023-comp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
